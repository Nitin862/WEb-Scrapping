{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fadafd5-e8b4-449c-999b-61e958cbb0f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ad6bfb9-b438-4f80-be26-10de51e307e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Web Scraping: The automated extraction of data from websites.\\nUses:\\nData Collection: Efficiently gather large datasets.\\nAutomation: Automate repetitive data retrieval.\\nResearch & Analysis: Collect data for analysis and reporting.\\nAreas of Use:\\n\\nE-Commerce: Price and product tracking.\\nSocial Media: User posts and engagement analysis.\\nNews & Media: Aggregating news articles and content.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Web Scraping: The automated extraction of data from websites.\n",
    "Uses:\n",
    "Data Collection: Efficiently gather large datasets.\n",
    "Automation: Automate repetitive data retrieval.\n",
    "Research & Analysis: Collect data for analysis and reporting.\n",
    "Areas of Use:\n",
    "\n",
    "E-Commerce: Price and product tracking.\n",
    "Social Media: User posts and engagement analysis.\n",
    "News & Media: Aggregating news articles and content.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f99a2e6f-4d30-45b6-a291-2c56f2a1cec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q2. What are the different methods used for Web Scraping?'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Q2. What are the different methods used for Web Scraping?'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "667a2fc2-899a-4518-b019-5ff950db7add",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Manual Scraping: Copying and pasting data directly from web pages.\\nHTML Parsing Libraries: Using libraries like BeautifulSoup (Python) or Cheerio (Node.js) to extract data from HTML.\\nWeb Scraping Frameworks: Utilizing frameworks like Scrapy (Python) or Puppeteer (Node.js) for structured scraping and automation.\\nAPIs: Accessing data through web APIs provided by websites, which is often more reliable and structured.\\nBrowser Automation Tools: Employing tools like Selenium or Playwright to interact with web pages and extract data dynamically.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Manual Scraping: Copying and pasting data directly from web pages.\n",
    "HTML Parsing Libraries: Using libraries like BeautifulSoup (Python) or Cheerio (Node.js) to extract data from HTML.\n",
    "Web Scraping Frameworks: Utilizing frameworks like Scrapy (Python) or Puppeteer (Node.js) for structured scraping and automation.\n",
    "APIs: Accessing data through web APIs provided by websites, which is often more reliable and structured.\n",
    "Browser Automation Tools: Employing tools like Selenium or Playwright to interact with web pages and extract data dynamically.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a274237-e309-4874-a78e-d7d2b7e80862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q3. What is Beautiful Soup? Why is it used?'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Q3. What is Beautiful Soup? Why is it used?'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83d1c3c3-3de2-4915-af94-c3ef5b8b80af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Beautiful Soup is a Python library used for parsing HTML and XML documents. It helps in extracting and navigating data from web pages. It’s often used for web scraping because it provides easy-to-use methods for searching and modifying the parse tree, handling poorly formed markup, and integrating with other libraries like requests for fetching web content.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Beautiful Soup is a Python library used for parsing HTML and XML documents. It helps in extracting and navigating data from web pages. It’s often used for web scraping because it provides easy-to-use methods for searching and modifying the parse tree, handling poorly formed markup, and integrating with other libraries like requests for fetching web content.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f7ed831-acfa-4804-889a-2fd62e81e957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q4. Why is flask used in this Web Scraping project?'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Q4. Why is flask used in this Web Scraping project?'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a6a0822-0de8-4a75-98a2-a4db1cfb957f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Flask is used in web scraping projects to create a lightweight web server or API for managing and serving scraped data. It allows developers to build a web interface for interacting with the scraped data, perform backend operations, and expose endpoints for data access, all with minimal overhead'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Flask is used in web scraping projects to create a lightweight web server or API for managing and serving scraped data. It allows developers to build a web interface for interacting with the scraped data, perform backend operations, and expose endpoints for data access, all with minimal overhead'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f41ca3ad-5c14-4303-8ecb-f1e70f91710e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q5. Write the names of AWS services used in this project. Also, explain the use of each service.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Q5. Write the names of AWS services used in this project. Also, explain the use of each service.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6370ffb6-f903-49ce-804e-9fa5b280494a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here are some AWS services commonly used in web scraping projects and their purposes:\\n\\nAmazon EC2: Provides scalable virtual servers to run web scraping scripts and applications.\\nAmazon S3: Stores and manages large amounts of data, including scraped data and logs.\\nAmazon RDS: Manages and scales relational databases to store structured data from web scraping.\\nAmazon Lambda: Runs code in response to events (e.g., scheduled scraping tasks) without managing servers.\\nAmazon CloudWatch: Monitors and logs the performance and health of web scraping applications and infrastructure.\\nAmazon SQS: Manages and queues messages between components of a distributed scraping system for reliable data processing.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Here are some AWS services commonly used in web scraping projects and their purposes:\n",
    "\n",
    "Amazon EC2: Provides scalable virtual servers to run web scraping scripts and applications.\n",
    "Amazon S3: Stores and manages large amounts of data, including scraped data and logs.\n",
    "Amazon RDS: Manages and scales relational databases to store structured data from web scraping.\n",
    "Amazon Lambda: Runs code in response to events (e.g., scheduled scraping tasks) without managing servers.\n",
    "Amazon CloudWatch: Monitors and logs the performance and health of web scraping applications and infrastructure.\n",
    "Amazon SQS: Manages and queues messages between components of a distributed scraping system for reliable data processing.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d91478-7191-49cd-98ee-9c29e9233c1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
